{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Host's ganglia transcriptome assembly\n",
        "In this notebook you can find the commands and scripts that were used for the transcriptome assembly.\n",
        "Input and output directories are specified under `### input ###` in every script. The path to the executable file of the program is specified in the `### soft ###` section of the script. More datails are noted in comments in every script."
      ],
      "metadata": {
        "id": "Ntj7RyXpUKQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library preparation\n",
        "### Data reformatting\n",
        "Here are scripts for analyzing female samples. For male samples directories paths should be changed.\n",
        "\n",
        "BBMap/BBTools (v. 39.01) was used for ID correction of short paired-end reads and filtering of rnaSPAdes results (removal of assembled sequences with unknown nucleotides).\n",
        "\n",
        "Script for BBTools:"
      ],
      "metadata": {
        "id": "h2ZjEGgXAJZJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Us5kFJHX8maN"
      },
      "outputs": [],
      "source": [
        "# !/bin/bash\n",
        "\n",
        "### INPUT ###\n",
        "\n",
        "INDIR=/home/al/Documents/projects/reticulata_data/females/input/ # Full path to the input directory\n",
        "OUTDIR=/home/al/Documents/projects/reticulata_data/females/output/ # Full path to the output directory\n",
        "SPTAG=PmPr_fem # Species tag\n",
        "OUTTAG=renamed_raw # Output files tag\n",
        "\n",
        "### SOFT ###\n",
        "\n",
        "BBTools_reformat=/home/al/Documents/Programs/BBMap_39.01/bbmap/reformat.sh\n",
        "\n",
        "### MAIN ###\n",
        "\n",
        "for dir in $(find $INDIR -mindepth 1 -type d); do\n",
        "    r1=\"$(find $dir -type f -name '*_R1.fq.gz')\"\n",
        "    r2=\"$(find $dir -type f -name '*_R2.fq.gz')\"\n",
        "    tag=$(basename $dir)\n",
        "    echo \"BBtools/reformat.sh starts to work with: \"\n",
        "    echo \"R1: $r1\"\n",
        "    echo \"R2: $r2\"\n",
        "    echo \"TAG: $tag\"\n",
        "    mkdir $OUTDIR/$tag\n",
        "    cd $OUTDIR/$tag\n",
        "    nohup $BBTools_reformat in=$r1 in2=$r2 out=${SPTAG}.${tag}.${OUTTAG}.R1.fq.gz out2=${SPTAG}.${tag}.${OUTTAG}.R2.fq.gz trimreaddescription=t addslash=t spaceslash=f\n",
        "    wait\n",
        "    cd ..\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Short paired-end reads libraries quality control and preparation\n",
        "\n",
        "FastQC (v. 0.12.1) was utilized to spot potential problems in sequencing datasets.\n",
        "\n",
        "FastQC launching command example:"
      ],
      "metadata": {
        "id": "HQmTbW6hCX5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fastqc -o infe_fem_fq_out *.fq.gz"
      ],
      "metadata": {
        "id": "Ae437C9hCvX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastP utility (v. 0.23.2) performed the low-quality and adapter sequences removal. Scripts are available in the repository. The trimming parameters was the following: `--cut_window_size 4 --cut_mean_quality 20 --qualified_quality_phred 20 --length_required 25`.\n",
        "\n",
        "FastP utility launching script:"
      ],
      "metadata": {
        "id": "87ReFJNiEZOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "### INPUT ###\n",
        "\n",
        "INDIR=/home/LVP/raw_data/rna/females/for_fastp # Full path to the input directory\n",
        "OUTDIR=/home/LVP/raw_data/rna/females/fastp_out # Full path to the output directory\n",
        "\n",
        "### Soft ###\n",
        "\n",
        "fastp=/home/LVP/Soft/fastp\n",
        "\n",
        "### PARAMS ###\n",
        "\n",
        "WIN_SIZE=4\n",
        "QUAL_QUAL=20\n",
        "MEAN_QUAL=20\n",
        "MIN_LEN=25\n",
        "THREADS=5\n",
        "\n",
        "### MAIN ###\n",
        "\n",
        "cd $OUTDIR\n",
        "\n",
        "for dir in $(find $INDIR -mindepth 1 -type d); do\n",
        "    r1=\"$(find $dir -type f -name '*R1.fq.gz')\"\n",
        "    r2=\"$(find $dir -type f -name '*R2.fq.gz')\"\n",
        "    tag=$(basename $dir)\n",
        "    echo \"FastP starts to work with: \"\n",
        "    echo \"R1: $r1\"\n",
        "    echo \"R2: $r2\"\n",
        "    echo \"TAG: $tag\"\n",
        "    echo \"Window size: $WIN_SIZE\"\n",
        "    echo \"Mean quality: $MEAN_QUAL\"\n",
        "    echo \"Qualified quality: $QUAL_QUAL\"\n",
        "    echo \"Min length: $MIN_LEN\"\n",
        "    echo \"Threads: $THREADS\"\n",
        "    mkdir ${tag}_fastP_output\n",
        "    cd ${tag}_fastP_output\n",
        "    nohup $fastp --in1 $r1 --out1 ${tag}.fastp_tmm.R1.fastq.gz --in2 $r2 --out2 ${tag}.fastp_tmm.R2.fastq.gz --unpaired1 ${tag}.fastp_unpaired1.fastq.gz --unpaired2 ${tag}.fastp_unpaired2.fastq.gz$\n",
        "    wait\n",
        "    cd ..\n",
        "done\n",
        "\n",
        "echo \"##### Job is complete #####\"\n"
      ],
      "metadata": {
        "id": "JAMhpN58EBJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decontamination via Kraken2\n",
        "Kraken2 (v. 2.1.2) is a taxonomic classification system using exact k-mer matches to achieve high accuracy and fast classification speeds. In our project, we used it to build a database of possible contamination (such as bacteria and viruses). We used standard database that includes libraries from archaea, viruses, bacteria, plasmid, fungi, human and protozoa. \n",
        "In case of transcriptomic short paired-end read libraries we added to standard database the early assembled transcriptomic data from the parasite *Peltogaster reticulata* ([Nesterenko, Miroliubov, 2023](https://f1000research.com/articles/11-583)) and the genomic sequences from another rhizocephalan species, *Sacculina carcini* ([Blaxter et al., *in press*](https://wellcomeopenresearch.org/articles/8-91)). "
      ],
      "metadata": {
        "id": "z4Sr9KNEE5S9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standard database downloading:"
      ],
      "metadata": {
        "id": "z67aK1gejC3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "### INPUT ###\n",
        "\n",
        "OUTDIR=/home/LVP/Kraken2_DB_reticulata/ # Full path to the directory where the database will be stored\n",
        "DBTAG=Kraken2_plus_db_reticulata # Some name of the database to be created\n",
        "\n",
        "### SOFT ###\n",
        "\n",
        "KRAKEN2DIR=/home/LVP/Soft/kraken2 # Full path to the directory where the Kraken2 executable files are stored\n",
        "\n",
        "### Processing ###\n",
        "\n",
        "mkdir -p $OUTDIR\n",
        "cd $OUTDIR\n",
        "\n",
        "nohup $KRAKEN2DIR/kraken2-build --download-taxonomy --db $DBTAG --threads 5 --use-ftp\n",
        "wait\n",
        "nohup $KRAKEN2DIR/kraken2-build --download-library archaea --db $DBTAG --threads 5\n",
        "wait\n",
        "nohup $KRAKEN2DIR/kraken2-build --download-library viral --db $DBTAG --threads 5\n",
        "wait\n",
        "nohup $KRAKEN2DIR/kraken2-build --download-library bacteria --db $DBTAG --threads 5\n",
        "wait\n",
        "nohup $KRAKEN2DIR/kraken2-build --download-library plasmid --db $DBTAG --threads 5\n",
        "wait\n",
        "nohup $KRAKEN2DIR/kraken2-build --download-library human --db $DBTAG --threads 5\n",
        "wait\n",
        "nohup $KRAKEN2DIR/kraken2-build --download-library fungi --db $DBTAG --threads 5\n",
        "wait\n",
        "nohup $KRAKEN2DIR/kraken2-build --download-library protozoa --db $DBTAG --threads 5\n",
        "wait\n",
        "nohup $KRAKEN2DIR/kraken2-build --download-library UniVec_Core --db $DBTAG --threads 5\n",
        "wait\n",
        "\n",
        "echo \"##### Job is complete #####\""
      ],
      "metadata": {
        "id": "dHWtkvBpjPgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Sacculina carcini* genome was added to standard database using the command:"
      ],
      "metadata": {
        "id": "9sN28FwdjWUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "/home/LVP/Soft/kraken2/kraken2-build --add-to-library /home/LVP/Source/Sacculina/Sacculinacarcini_ref_genes.with_taxid.fasta --db /home/LVP/kraken2_db_females/Kraken2_plus_db_reticulata --threads 10"
      ],
      "metadata": {
        "id": "Bu-gY8IDdeFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build database:"
      ],
      "metadata": {
        "id": "GmlXh0HPlYq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !/bin/bash\n",
        "\n",
        "### INPUT ###\n",
        "\n",
        "OUTDIR=/home/LVP/kraken2_fem # Full path to the directory where the database will be stored\n",
        "DBTAG=/home/LVP/kraken2_db_females/Kraken2_plus_db_reticulata # Some name of the database to be created\n",
        "\n",
        "### SOFT ###\n",
        "\n",
        "KRAKEN2DIR=/home/LVP/Soft/kraken2 # Full path to the directory where the Kraken2 executable files are stored\n",
        "\n",
        "### Processing ###\n",
        "\n",
        "cd $OUTDIR\n",
        "\n",
        "nohup $KRAKEN2DIR/kraken2-build --build --db $DBTAG --threads 12\n",
        "wait\n",
        "\n",
        "echo \"##### Job is complete #####\""
      ],
      "metadata": {
        "id": "9RGNbUrNlXdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decontamination:"
      ],
      "metadata": {
        "id": "Cztf_6L-lniB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "### Input ###\n",
        "\n",
        "FASTPDIR=/home/LVP/fastp/rna/females/ # Full path to the directory where the fastP results are stored\n",
        "OUTDIR=/home/LVP/kraken2_outputs/females_kraken2_output/ # Full path to the directory where the classification results (Kraken2 output) will be stored\n",
        "DBDIR=/home/LVP/kraken2_db_females # Full path to the directory where the database is stored\n",
        "DBTAG=Kraken2_plus_db_reticulata # Some name of the database that will be used\n",
        "SUFFIX=#\n",
        "\n",
        "### SOFT ###\n",
        "\n",
        "KRAKEN2DIR=/home/LVP/Soft/kraken2 # Full path to the directory where the Kraken2 executable files are stored\n",
        "\n",
        "### Processing ###\n",
        "\n",
        "mkdir -p $OUTDIR\n",
        "cd $OUTDIR\n",
        "\n",
        "for dir in $(find $FASTPDIR -mindepth 1 -type d); do\n",
        "        r1=\"$(find $dir -type f -name '*fastp_tmm.R1.fastq.gz')\"\n",
        "        r2=\"$(find $dir -type f -name '*fastp_tmm.R2.fastq.gz')\"\n",
        "        tag=$(basename $dir)\n",
        "        echo \"Kraken2 starts to work with: \"\n",
        "        echo \"R1: $r1\"\n",
        "        echo \"R2: $r2\"\n",
        "        echo \"TAG: $tag\"\n",
        "      \tmkdir ${tag}_vs_${DBTAG}\n",
        "      \tcd ${tag}_vs_${DBTAG}\n",
        "        nohup $KRAKEN2DIR/kraken2 --db ${DBDIR}/${DBTAG}/ --threads 12 --paired --gzip-compressed --unclassified-out ${tag}.unclass.R${SUFFIX}.fastq --classified-out ${tag}.class.R${SUFFIX}.fastq --output ${tag}_vs_${DBTAG}.tab --report ${tag}_vs_${DBTAG}.report ${r1} ${r2}\n",
        "\t      cd ..\n",
        "        wait\n",
        "done\n",
        "\n",
        "echo \"##### Job is complete #####\""
      ],
      "metadata": {
        "id": "nq3-oEq7lmpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results were visualized by Pavian (v. 1.0) using Kraken2 output files `.report` for every sample."
      ],
      "metadata": {
        "id": "dONfJzKiLWCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assembly\n",
        "We performed *de novo* transcriptome assembly using 3 tools (rnaSPAdes, RNA-Bloom, and Trinity) in order to receive the best results using the strengths of different assemblers.\n",
        "\n",
        "**Before assemblying we merged all prepared short paired-end read libraries from healthy and infected female and male crabs into the single fastq files.**\n"
      ],
      "metadata": {
        "id": "A5kHmlPRWIFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### rnaSPAdes\n",
        "\n",
        "rnaSPAdes (SPAdes v. 3.15.4) with default options was used. The script is available below."
      ],
      "metadata": {
        "id": "yi57XNUEWP_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "### INPUT ###\n",
        "R1=/home/LVP/assembly/ganglia.merged.R1.fastq # Full path to the merged decontaminated (after Kraken2) R1 fastq file\n",
        "R2=/home/LVP/assembly/ganglia.merged.R2.fastq # Full path to the merged decontaminated (after Kraken2) R2 fastq file\n",
        "OUTDIR=/home/LVP/assembly/ganglia_ref_rnaSPAdes # Full path to the directory where the assembling output will be stored\n",
        "\n",
        "### SOFT ###\n",
        "\n",
        "SPADES=/home/LVP/Soft/SPAdes-3.15.4-Linux/bin/rnaspades.py\n",
        "\n",
        "### MAIN ###\n",
        "echo \"***** rnaSPAdes began to work with params: *****\"\n",
        "echo \"R1: $R1\"\n",
        "echo \"R2: $R2\"\n",
        "echo \"OUTDIR: $OUTDIR\"\n",
        "mkdir $OUTDIR\n",
        "nohup $SPADES -1 $R1 -2 $R2 --ss fr --threads 24 --memory 100 -o $OUTDIR\n",
        "wait\n",
        "echo \"##### Job is complete #####\"\n"
      ],
      "metadata": {
        "id": "I3zZMmT0WIZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNA-Bloom\n",
        "RNA-Bloom (v. 2.0.1) was installed using mamba (v. 1.4.1). Specified options was` --kmer 25` `--percent 0.90` `--length 200`. The script is the following."
      ],
      "metadata": {
        "id": "CGU2PfOpWxUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "### INPUT ###\n",
        "\n",
        "R1=/home/LVP/assembly/ganglia.merged.R1.fastq  # Full path to the merged decontaminated (after Kraken2) R1 fastq file\n",
        "R2=/home/LVP/assembly/ganglia.merged.R2.fastq  # Full path to the merged decontaminated (after Kraken2) R2 fastq file\n",
        "OUTTAG=ganglia_ref_rnabloom # Some name of the assembly. For example, Pret_ref_rnabloom\n",
        "OUTDIR=/home/LVP/assembly/ganglia_ref_rnabloom # Full path to the directory where the assembling output will be stored\n",
        "\n",
        "### SOFT ###\n",
        "\n",
        "RNABLOOM=/home/lianguzova/mambaforge/bin/rnabloom # Full path to the RNA-Bloom\n",
        "\n",
        "### MAIN ###\n",
        "echo \"***** RNA-Bloom began to work with params: *****\"\n",
        "echo \"R1: $R1\"\n",
        "echo \"R2: $R2\"\n",
        "echo \"OUTTAG: $OUTTAG\"\n",
        "echo \"OUTDIR: $OUTDIR\"\n",
        "\n",
        "mkdir $OUTDIR\n",
        "nohup $RNABLOOM --left $R1 --right $R2 --revcomp-right --name $OUTTAG --threads 24 --outdir $OUTDIR --kmer 25 --memory 100 --percent 0.90 -length 200\n",
        "wait\n",
        "echo \"##### Job is complete #####\"\n"
      ],
      "metadata": {
        "id": "3m1QPFDUWwsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trinity\n",
        "Trinity (v. 2.14.0) was utilised. We also installed the tool dependencies using conda (v. 23.1.0) into special virtual environment. Here is the script that was used:"
      ],
      "metadata": {
        "id": "8LV5PkfDYB1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "# INPUT: #\n",
        "R1=/home/LVP/assembly/ganglia.merged.R1.fastq # Full path to the merged decontaminated (after Kraken2) R1 fastq file\n",
        "R2=/home/LVP/assembly/ganglia.merged.R2.fastq # Full path to the merged decontaminated (after Kraken2) R2 fastq file\n",
        "OUTTAG=trinity_ass # Some name of the assembly. For example, Pret_ref_Trinity\n",
        "OUTDIR=/home/LVP/assembly/ganglia_ref_trinity_please  # Full path to the directory where the assembling output will be stored\n",
        "\n",
        "### SOFT ###\n",
        "\n",
        "TRINITY=/home/LVP/Soft/trinityrnaseq-v2.14.0/Trinity # Full path to the Trinity\n",
        "\n",
        "### MAIN ###\n",
        "echo \"***** Trinity began to work with params: *****\"\n",
        "echo \"R1: $R1\"\n",
        "echo \"R2: $R2\"\n",
        "echo \"OUTTAG: $OUTTAG\"\n",
        "echo \"OUTDIR: $OUTDIR\"\n",
        "\n",
        "source activate /home/LVP/Soft/exit/envs/trinity_env # conda env\n",
        "\n",
        "cd $OUTDIR\n",
        "\n",
        "nohup $TRINITY --seqType fq --max_memory 100G --left $R1 --right $R2 --SS_lib_type FR --CPU 24 --min_contig_length 200 --output $OUTTAG --full_cleanup\n",
        "wait\n",
        "echo \"##### Job is complete #####\""
      ],
      "metadata": {
        "id": "3A3UgLMXYCxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***In further analysis, we considered only sequences with a length of at least 200 nucleotides.*** To filter the assembly results, we used the python script to the all obtained transcriptomic assemblies:"
      ],
      "metadata": {
        "id": "dup9OezRwE9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import argparse\n",
        "except ImportError:\n",
        "    print(\"Please check if module 'argparse' is installed\")\n",
        "    quit()\n",
        "\n",
        "from Bio import SeqIO\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--fasta', type=argparse.FileType('r'), required=True)\n",
        "parser.add_argument('--min_len', type=str, required=True)\n",
        "parser.add_argument('--out', type=str, required=True)\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    fasta_seqs = SeqIO.parse(args.fasta, \"fasta\")\n",
        "    with open(\"{output}.fasta\".format(output=args.out), 'a') as output:\n",
        "        for fasta in fasta_seqs:\n",
        "            name, sequence = fasta.id, fasta.seq\n",
        "            if len(sequence) >= int(args.min_len):\n",
        "                output.write(\">{name}\\n{seq}\\n\".format(name=name, seq=sequence))"
      ],
      "metadata": {
        "id": "njdDHrCAwNCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clusterization\n",
        "\n",
        "CD-HIT-est (v. 4.8.1) was used to the three transcriptome assemblies separate clusterization. Clusters with 95% identity were gathered, comparison of both strand (+/+, +/-) was performed. An example script is shown below:"
      ],
      "metadata": {
        "id": "BF102e4QDHWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "# INPUT: #\n",
        "\n",
        "FASTA=/home/LVP/assembly/ganglia_ref_trinity_please/filtred.fasta\n",
        "TAG=Pdum_new_ref_trinity.cdhit_c95\n",
        "OUTDIR=/home/LVP/assembly/trinity_cdhit_95_200\n",
        "\n",
        "# SOFT: #\n",
        "\n",
        "source activate /home/LVP/Soft/exit/envs/cdhit_env\n",
        "\n",
        "# MAIN: #\n",
        "\n",
        "cd $OUTDIR\n",
        "\n",
        "echo \"***** CDHIT began to work with params: *****\"\n",
        "echo \"FASTA: $FASTA\"\n",
        "echo \"TAG: $TAG\"\n",
        "echo \"OUTDIR: $OUTDIR\"\n",
        "nohup /home/LVP/Soft/exit/envs/cdhit_env/bin/cd-hit-est -i $FASTA -o ${TAG}.fasta -c 0.95 -T 24 -d 0 -g 1 -r 1 -M 5000\n",
        "wait\n",
        "echo \"##### Job is complete #####\""
      ],
      "metadata": {
        "id": "qR_nc5PADEzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assembly quality control\n"
      ],
      "metadata": {
        "id": "s49AA9dkYV3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TransRate (v. 1.0.1) was utilised for the qualitative analysis of *de novo* transcriptome assemblies.\n",
        "\n",
        "The default options were used; the following scripts for Trinity output can be used as a template for other assemblers. \n",
        "\n",
        "**Only the sequences with high quality and assembly completeness (“good” according to the TransRate classification) were used in the following analysis.**"
      ],
      "metadata": {
        "id": "7_oBS0wBYVtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "### INPUT ###\n",
        "\n",
        "R1=/home/LVP/assembly/ganglia.merged.R1.fastq # Full path to the decontaminated and merged R1 fastq file\n",
        "R2=/home/LVP/assembly/ganglia.merged.R2.fastq # Full path to the decontaminated and merged R2 fastq file\n",
        "Contigs=/home/LVP/assembly/trinity_cdhit_95_200/Pdum_new_ref_trinity.cdhit_c95.fasta # Full path to the fasta file with assembled contigs (length >= 200 bp)\n",
        "OUTDIR=/home/gafarova/trinity_TransRate_output # Full path to the directory where the quality control results will be stored\n",
        "\n",
        "### SOFT ##\n",
        "\n",
        "source activate /home/LVP/Soft/exit/envs/transrate_env # Full path to the TransRate virtual environment\n",
        "\n",
        "TRANSRATE=/home/LVP/Soft/transrate-1.0.1/bin/transrate # Full path to TransRate software\n",
        "\n",
        "### MAIN ###\n",
        "\n",
        "echo \"***** TransRate (v1.0.1) began to work with params: *****\"\n",
        "echo \"R1: $R1\"\n",
        "echo \"R2: $R2\"\n",
        "echo \"Assembly: $Contigs\"\n",
        "cd $OUTDIR\n",
        "nohup ${TRANSRATE} --assembly=$Contigs --left=$R1 --right=$R2 --threads=24 --output=${OUTDIR}\n",
        "wait\n",
        "echo \"##### =^^= Job is complete #####\""
      ],
      "metadata": {
        "id": "5op9FUUCYp6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All the contigs with high rates of quality and assembly completeness were merged using basic UNIX-commands.**"
      ],
      "metadata": {
        "id": "-UQG7lKvZNKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clusterization\n",
        "\n",
        "Transcriptome redundancy reduction was performed using CD-HIT clusterization with minimal 95% identity between contigs and both strand comparison. The script:"
      ],
      "metadata": {
        "id": "YcjI7jDJZNEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "# INPUT: #\n",
        "\n",
        "FASTA=/home/LVP/assembly/whole_assembly.fasta\n",
        "TAG=whole_assembly_CDHIT\n",
        "OUTDIR=/home/LVP/assembly/CDHIT_whole_cluster_95_percent\n",
        "\n",
        "# SOFT: #\n",
        "\n",
        "source activate /home/lianguzova/mambaforge/envs/cdhit_env\n",
        "\n",
        "# MAIN: #\n",
        "\n",
        "mkdir $OUTDIR\n",
        "cd $OUTDIR\n",
        "\n",
        "echo \"***** CDHIT began to work with params: *****\"\n",
        "echo \"FASTA: $FASTA\"\n",
        "echo \"TAG: $TAG\"\n",
        "echo \"OUTDIR: $OUTDIR\"\n",
        "nohup /home/lianguzova/mambaforge/envs/cdhit_env/bin/cd-hit-est -i $FASTA -o ${TAG}.fasta -c 0.95 -T 24 -d 0 -g 1 -r 1 -M 5000\n",
        "wait\n",
        "echo \"##### Job is complete #####\""
      ],
      "metadata": {
        "id": "yNverPd0ZZB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transcriptome assemblies completeness control\n",
        "\n",
        "Benchmarking Universal Single-Copy Ortholog (BUSCO) (v. 5.4.7) was used for the transcriptome assemblies completeness control via the searching of metazoan single-copy orthologs. The transcriptome mode was selected (`-m transcriptome`), and Metazoa OrthoDB (v. 10) was used as lineage dataset. The template script is below. The Venn diagram visualization was created using [InteractiVenn](http://www.interactivenn.net/)."
      ],
      "metadata": {
        "id": "bdJ5-Y_YZkha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "source activate busco_env\n",
        "\n",
        "workdir=/home/LVP/busco/\n",
        "\n",
        "cd $workdir\n",
        "\n",
        "# INPUT: #\n",
        "Contigs=/home/LVP/assembly/CDHIT_whole_cluster_95_percent/whole_assembly_CDHIT.fasta \n",
        "TAG=good_Pret_new_ref_whole_assembly_vs_Metazoa_odb10\n",
        "DB=/home/LVP/Source/BUSCO/metazoa_odb10\n",
        "\n",
        "# Analysis: #\n",
        "echo \"***** BUSCO began to work with params: *****\"\n",
        "echo \"DB: $DB\"\n",
        "echo \"TAG: $TAG\"\n",
        "echo \"Assembly: $Contigs\"\n",
        "nohup /home/lianguzova/mambaforge/envs/busco_env/bin/busco -m transcriptome -i $Contigs -o $TAG -l $DB --cpu 12\n",
        "wait\n",
        "echo \"##### Job is complete #####\""
      ],
      "metadata": {
        "id": "EmJxqpobakXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantifying transcripts expression\n",
        "Salmon (v. 1.10.1) installed in special conda environment mapped the short paired-end reads libraries to the reference transcriptome assembly."
      ],
      "metadata": {
        "id": "CqsurKq5Zkey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The script allowing to create an index for the reference transcriptome:\n"
      ],
      "metadata": {
        "id": "PFvUtyjKcPIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "workdir=/home/LVP/salmon_cleaned_assembly\n",
        "\n",
        "cd $workdir\n",
        "\n",
        "# INPUT: #\n",
        "FASTA=/home/LVP/assembly/cleaned/cleaned_assembly.fasta\n",
        "TAG=good_Pdum_new_ref_index\n",
        "\n",
        "echo \"***** Salmon (index) began to work with params: *****\"\n",
        "echo \"FASTA: $FASTA\"\n",
        "echo \"TAG: $TAG\"\n",
        "nohup salmon index --transcripts ${FASTA} --kmerLen 25 --index ${TAG} --threads 10\n",
        "wait\n",
        "echo \"##### Job is complete #####\""
      ],
      "metadata": {
        "id": "7ImUPPUGcdAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapping of the paired-end reads and the sequences expression quantification was performed using the following script for the data from the female hermit crabs, which can be changed for the males."
      ],
      "metadata": {
        "id": "VHNkyNgGccV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "### INPUT: ###\n",
        "tmmdir=/home/LVP/kraken2_outputs/females_kraken2_output\n",
        "outdir=/home/LVP/salmon_cleaned_assembly/\n",
        "index=/home/LVP/salmon_cleaned_assembly/good_Pdum_new_ref_index\n",
        "\n",
        "### Analyses ###\n",
        "\n",
        "cd $outdir\n",
        "\n",
        "for dir in $(find $tmmdir -mindepth 1 -type d); do\n",
        "    r1=\"$(find $dir -type f -name '*class.R_1.fastq')\" \n",
        "    r2=\"$(find $dir -type f -name '*class.R_2.fastq')\"\n",
        "    tag=$(basename -- $dir _vs_PlusPF_db)\n",
        "    echo \"Salmon quant starts to work with: \"\n",
        "    echo \"R1: $r1\"\n",
        "    echo \"R2: $r2\"\n",
        "    echo \"TAG: $tag\"\n",
        "    echo \"Ref_index: $index\"\n",
        " nohup salmon quant -i ${index} -l A -1 $r1 -2 $r2 -o ${tag}_quant --seqBias --gcBias --minScoreFraction 0.50 --softclip --threads 12 --validateMappings --writeUnmappedNames\n",
        "    wait\n",
        "done\n",
        "\n",
        "echo \"##### Job is complete =^_^= #####\""
      ],
      "metadata": {
        "id": "O6i9JU7Scktn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Determination of assembly translation products\n",
        "\n",
        "TransDecoder (v. 5.5.0) identified candidate coding regions within transcript sequences. Initial identification of open reading frames (ORFs) and translation products was performed using following script:\n"
      ],
      "metadata": {
        "id": "CXXemERLdM-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "source activate transdecoder_env\n",
        "\n",
        "workdir=/home/LVP/transdecoder/cleaned/again\n",
        "\n",
        "cd $workdir\n",
        "\n",
        "# INPUT: #\n",
        "FASTA=/home/LVP/assembly/CDHIT_cleaned_cluster_95_percent/cleaned_assembly_CDHIT.fasta  \n",
        "\n",
        "# Analysis: #\n",
        "echo \"***** TransDecoder.LongORFs began to work with params: *****\"\n",
        "echo \"FASTA: $FASTA\"\n",
        "nohup /home/lianguzova/mambaforge/envs/transdecoder_env/bin/TransDecoder.LongOrfs -t $FASTA -m 100 -G universal\n",
        "wait\n",
        "echo \"##### Job is complete #####\""
      ],
      "metadata": {
        "id": "QToug25LdNr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HMMER (v. 3.3.2) was used to compare found ORFs translation products with Pfam-A database using the following script. "
      ],
      "metadata": {
        "id": "bvQ6wbj-eZmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "source activate transdecoder_env\n",
        "\n",
        "workdir=/home/LVP/transdecoder/cleaned\n",
        "\n",
        "# INPUT: #\n",
        "FASTA=/home/LVP/transdecoder/cleaned/cleaned_assembly_CDHIT.fasta.transdecoder_dir/longest_orfs.pep\n",
        "TAG=pfama_pret_cleaned\n",
        "\n",
        "# Analysis: #\n",
        "cd $workdir\n",
        "echo \"***** HMMsearch began to search (vs PfamA) with params: *****\"\n",
        "echo \"FASTA: $FASTA\"\n",
        "echo \"TAG: $TAG\"\n",
        "nohup /home/lianguzova/mambaforge/envs/transdecoder_env/bin/hmmsearch --cpu 12 --domtblout ${TAG}_longORFs_vs_pfam.domtblout /home/LVP/Source/Pfam-A.hmm $FASTA\n",
        "wait\n",
        "echo \"##### Job is complete #####\""
      ],
      "metadata": {
        "id": "8grf_5qagu2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison of amino acid sequences with the UniRef90 database was performed using the DIAMOND (v. 2.0.15) program. The script used is shown below:"
      ],
      "metadata": {
        "id": "mSSPdGbLhpyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "source activate diamond_env\n",
        "\n",
        "workdir=/home/LVP/transdecoder/cleaned\n",
        "\n",
        "# INPUT: #\n",
        "FASTA=/home/LVP/transdecoder/cleaned/cleaned_assembly_CDHIT.fasta.transdecoder_dir/longest_orfs.pep\n",
        "DB=/home/LVP/transdecoder/uniref\n",
        "TAG=Uniref_Pret_cleaned\n",
        "\n",
        "# Analysis: #\n",
        "echo \"***** DIAMOND BLASTp began to search (vs UniRef90) with params: *****\"\n",
        "echo \"FASTA: $FASTA\"\n",
        "echo \"DB: $DB\"\n",
        "echo \"TAG: $TAG\"\n",
        "nohup /home/lianguzova/mambaforge/envs/diamond_env/bin/diamond blastp --db $DB --query $FASTA --threads 12 --out ${workdir}/${TAG}_longest_orfs_vs_UniRef90.diamond.outfmt6 --outfmt 6 --max-target-seqs 1 --evalue 1e-5\n",
        "wait\n",
        "echo \"##### Job is complete #####\""
      ],
      "metadata": {
        "id": "6KeJInvvhrjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refinement of ORFs translation products was performed using the results of comparison with databases:"
      ],
      "metadata": {
        "id": "h-GSVBBDh49b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/bin/bash\n",
        "\n",
        "source activate transdecoder_env\n",
        "\n",
        "workdir=/home/LVP/transdecoder/cleaned/\n",
        "\n",
        "cd $workdir\n",
        "\n",
        "# INPUT: #\n",
        "FASTA=/home/LVP/assembly/CDHIT_cleaned_cluster_95_percent/cleaned_assembly_CDHIT.fasta  \n",
        "PFAM=/home/LVP/transdecoder/cleaned/pfama_pret_cleaned_longORFs_vs_pfam.domtblout\n",
        "BLASTP=/home/LVP/transdecoder/cleaned/Uniref_Pret_cleaned_longest_orfs_vs_UniRef90.diamond.outfmt6\n",
        "\n",
        "# Analysis: #\n",
        "echo \"***** TransDecoder.Predict began to work with params: *****\"\n",
        "echo \"FASTA: $FASTA\"\n",
        "echo \"PFAM: $PFAM\"\n",
        "echo \"BLASTP: $BLASTP\"\n",
        "nohup /home/lianguzova/mambaforge/envs/transdecoder_env/bin/TransDecoder.Predict -t $FASTA --retain_pfam_hits $PFAM --retain_blastp_hits $BLASTP\n",
        "wait\n",
        "echo \"##### Job is complete #####\""
      ],
      "metadata": {
        "id": "04Y9iJNqh8aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation of protein-coding sequences reference set\n",
        "\n",
        "We selected transcripts encoding proteins consisting of more than 100 amino acids and with the expression level more than 2 transcripts per million (TPM) (According to the Wagner, Kin & Lynch (2013) publication, “genes with more than two transcripts per million transcripts (TPM) are highly likely from actively transcribed genes.”) at least in one sample analysed using the provided steps:"
      ],
      "metadata": {
        "id": "aSK7hopZiRDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scripts for sorting transcripts and proteins `.fasta` files and expression levels `.csv` files"
      ],
      "metadata": {
        "id": "Zp3SF1lXBTrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "import re"
      ],
      "metadata": {
        "id": "NLTu8DiUjz_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select transcripts with a significant level of expression\n",
        "Select from the expression-averaged table the identifiers of those sequences that have an expression level of at least 2 TPM in at least 1 sample."
      ],
      "metadata": {
        "id": "6iSh_0SCklcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('mean_expression_data.csv', delimiter=',')\n",
        "data = data.query(\"healthy_fem>=2  or infected_fem>=2 or healthy_male>=2 or infected_male>=2\")\n",
        "data.to_csv('overexpressed.csv', index=False)"
      ],
      "metadata": {
        "id": "VmHyeDokbI4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select long protein products\n",
        "Select sequence identifiers that encode proteins at least 100 a.a. long"
      ],
      "metadata": {
        "id": "E6LW7LVmjmqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=['Name', 'Prot_name', 'Length'])\n",
        "for record in SeqIO.parse(\"cleaned_assembly_proteins.fasta\", \"fasta\"):\n",
        "    name = re.split('\\.p[\\d]+$', record.id)[0]\n",
        "    prot_num = record.id\n",
        "    seq_len = len(record.seq)\n",
        "    if seq_len >= 100:\n",
        "        new_row = {'Name': name, 'Prot_name': prot_name, 'Length': seq_len}\n",
        "        df = df._append(new_row, ignore_index=True)\n",
        "\n",
        "df.to_csv('fasta_prot_id.csv', index=False)"
      ],
      "metadata": {
        "id": "E7TOK9FKbVfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge identifiers that encode long proteins products and transcripts with significant expression levels"
      ],
      "metadata": {
        "id": "PGnnMgGujtq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prot_num(x):\n",
        "    y = re.search('\\.p([\\d]+)$', x)\n",
        "    if y is None:\n",
        "        return x\n",
        "    else:\n",
        "        return y.groups()[0]\n",
        "\n",
        "data1 = pd.read_csv('fasta_prot_id.csv', delimiter=',')\n",
        "data1['Prot_num'] = data1.apply(lambda row: get_prot_num(row['Prot_name']), axis=1)\n",
        "names_list = data1.Name.unique()\n",
        "print(data1.head())\n",
        "data1 = data1.sort_values(by=['Prot_num'], kind='stable')\n",
        "data1 = data1.sort_values(by=['Length'], kind='stable', ascending=False)\n",
        "data1 = data1.sort_values(by=['Name'], kind='stable')\n",
        "data1 = data1.reset_index(drop=True)\n",
        "print(len(data1.Name.unique()))\n",
        "data1 = data1[~data1.duplicated(subset=['Name'])]\n",
        "\n",
        "data2 = pd.read_csv('overexpressed.csv', delimiter=',')\n",
        "\n",
        "data = pd.merge(data1, data2)\n",
        "data.to_csv('merged.csv', index=False)"
      ],
      "metadata": {
        "id": "UayTbMlWblmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make new expression tables"
      ],
      "metadata": {
        "id": "EGcym2UXkarU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('merged.csv', delimiter=',')\n",
        "ids = data.Name\n",
        "new_names = pd.DataFrame({'New_name': ['Pmin_ref_seq_' + str(i+1) for i in range(len(ids))]})\n",
        "new_names_dict = pd.concat([pd.DataFrame({'Name': ids}), new_names], axis=1)\n",
        "print(new_names_dict.head(10))\n",
        "print(len(new_names_dict))\n",
        "table1 = pd.read_csv('expression_data.csv', delimiter=',')\n",
        "table2 = pd.read_csv('mean_expression_data.csv', delimiter=',')\n",
        "new_table1 = pd.merge(new_names_dict, table1, how='left')\n",
        "new_table1 = new_table1.drop('Name', axis=1)\n",
        "new_table1.rename(columns={'New_name': 'Name'}, inplace=True)\n",
        "new_table1.to_csv('new_expression_data.csv', index=False)\n",
        "new_table2 = pd.merge(new_names_dict, table2, how='left')\n",
        "new_table2 = new_table2.drop('Name', axis=1)\n",
        "new_table2.rename(columns={'New_name': 'Name'}, inplace=True)\n",
        "new_table2.to_csv('new_mean_expression_data.csv', index=False)"
      ],
      "metadata": {
        "id": "gSrYN3K2bpue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make new `.fasta` protein file"
      ],
      "metadata": {
        "id": "OW1WZpuOkbX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('merged.csv', delimiter=',')\n",
        "ids = data.Name\n",
        "prot_ids = data.Prot_name\n",
        "new_names = pd.DataFrame({'New_name': ['Pmin_ref_seq_' + str(i+1) for i in range(len(data))]})\n",
        "new_names_dict = pd.concat([pd.DataFrame({'Name': ids}), pd.DataFrame({'Prot_name': prot_ids}), new_names], axis=1)\n",
        "records = []\n",
        "for record in SeqIO.parse(\"cleaned_assembly_proteins.fasta\", \"fasta\"):\n",
        "    id = record.id\n",
        "    if id in list(new_names_dict['Prot_name']):\n",
        "        record.description = record.description.replace(record.id, '')[1::]\n",
        "        record.id = new_names_dict.loc[new_names_dict['Prot_name'] == id].iloc[0]['New_name']\n",
        "        records.append(record)\n",
        "SeqIO.write(records, \"new_assembly_proteins.fasta\", \"fasta\")"
      ],
      "metadata": {
        "id": "oa2j2IulbtKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make new `.fasta` transcripts file"
      ],
      "metadata": {
        "id": "HiCgMXpzkgbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('merged.csv', delimiter=',')\n",
        "ids = data.Name\n",
        "new_names = pd.DataFrame({'New_name': ['Pmin_ref_seq_' + str(i+1) for i in range(len(data))]})\n",
        "new_names_dict = pd.concat([pd.DataFrame({'Name': ids}), new_names], axis=1)\n",
        "records = []\n",
        "for record in SeqIO.parse(\"cleaned_assembly.fasta\", \"fasta\"):\n",
        "    id = record.id\n",
        "    if id in list(new_names_dict['Name']):\n",
        "        record.description = record.description.replace(record.id, '')[1::]\n",
        "        record.id = new_names_dict.loc[new_names_dict['Name'] == id].iloc[0]['New_name']\n",
        "        records.append(record)\n",
        "SeqIO.write(records, \"new_assembly.fasta\", \"fasta\")"
      ],
      "metadata": {
        "id": "1mupFF4Lb4U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Protein-coding sequences functional annotation\n",
        "\n",
        "[EggNOG-mapper](http://eggnog-mapper.embl.de/) (v. 2.1.9) was used to annotate the obtained proteins. EggNOG database contains information about the orthologs of various organisms, the participation of the sequences in the biological processes, and the presence of certain protein domains."
      ],
      "metadata": {
        "id": "NxujXLOyjuIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Protein-coding sequences differential expression analysis\n",
        "\n",
        "RNentropy was utilised for the detection of significant variation of protein-coding sequences expression. The analysis was conducted using R (v. 4.2.3), the scripts here are only for female crabs."
      ],
      "metadata": {
        "id": "bLskatrxkK_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "### Libraries ###\n",
        "library(RNentropy)\n",
        "library(dplyr)\n",
        "\n",
        "### Input data ###\n",
        "expr_unaveraged <- read.csv2(\"data/new_expression_data.csv\", \n",
        "                             header = T, sep=\",\", row.names = 1)\n",
        "expr_averaged <- read.csv2(\"data/new_mean_expression_data.csv\", \n",
        "                           header = T, sep=\",\", row.names = 1)\n",
        "colnames(expr_unaveraged) <- c(\"Im_12\", \"If_11\", \n",
        "                               \"Hm_2\", \"If_3\", \"Im_4\", \n",
        "                               \"Hm_10\", \"Hf_1\")\n",
        "Healthy_fem <- c(0, 0, 1)\n",
        "Infected_fem <- c(1, 1, 0)\n",
        "Sample <- c(\"If_11\", \"If_3\", \"Hf_1\")  \n",
        "design <- data.frame(Sample, Healthy_fem, Infected_fem)\n",
        "design_matrix <- design\n",
        "rownames(design_matrix) <- Sample\n",
        "design_matrix <- design_matrix[, c(2, 3)]\n",
        "species_tag <- \"Pmin\"\n",
        "\n",
        "# Mutate #\n",
        "\n",
        "expr_females <- expr_unaveraged %>% select(all_of(Sample)) \n",
        "expr_females <- mutate_all(expr_females, function(x) as.numeric(as.character(x)))\n",
        "expr_females$GeneIDs <- as.factor(rownames(expr_females))\n",
        "design_matrix <- data.matrix(design_matrix, rownames.force = T)\n",
        "\n",
        "### Analysis ###\n",
        "# compute statistics and p-values\n",
        "RNresults <- RN_calc(expr_females, design = design_matrix)\n",
        "# select only genes with significant changes of expression\n",
        "# select sequences with global p-value lower than an user defined threshold \n",
        "# and provide a summary of over- and under-expression accoding to local p-values\n",
        "RNresults_selected <- RN_select(RNresults, gpv_t = 0.01, \n",
        "                                lpv_t = 0.01, method = 'BH')\n",
        "######\n",
        "# NB! Был добавлен новый df - selected:\n",
        "# Transcripts/genes with a corrected global p-value lower than gpv_t. \n",
        "# For each condition it will contain a column where values can be -1,0,1 or NA. \n",
        "# 1 means that all the replicates of this condition have expression value higher than the\n",
        "# average and local p-value <= lpv_t (thus the corresponding gene will be over-expressed in this condition). \n",
        "# -1 means that all the replicates of this condition have expression value lower than the average and local p-value <= lpv_t (thus\n",
        "# the corresponding gene will be under-expressed in this condition). \n",
        "# 0 means that at least one of the replicates has a local p-value > lpv_t. \n",
        "# NA means that the local p-values of the replicates are not consistent for this condition, that is, at least\n",
        "# one replicate results to be over-expressed and at least one results to be under-expressed.\n",
        "#######\n",
        "RNresults_significant <- RNresults_selected$selected\n",
        "write.table(RNresults_significant, \n",
        "            file=sprintf(\"%s_RNentropy_significant_results.tsv\", species_tag),\n",
        "            sep=\"\\t\", col.names = T, row.names = F)\n",
        "\n",
        "### Subset over-expressed genes only ###\n",
        "colnames(RNresults_significant)\n",
        "\n",
        "for (sample in c(\"Healthy_fem\", \"Infected_fem\")){\n",
        "  sample_overexpr <- subset(RNresults_significant, \n",
        "                            RNresults_significant[[sample]] == \"1\")\n",
        "  write.table(sample_overexpr, file=sprintf(\"%s_%s_RNentropy_overexp.tsv\", \n",
        "                                            species_tag, sample),  sep=\"\\t\", \n",
        "              col.names = T, row.names = F)\n",
        "}\n",
        "\n",
        "### Compute point mutual information matrix for the experimental conditions ###\n",
        "RNresults_pmi <- RN_pmi(RNresults)\n",
        "RNresults_npmi_matrix <- RNresults_pmi$npmi\n",
        "write.table(RNresults_npmi_matrix, file=sprintf(\"%s_RNentropy_npmi.tsv\", \n",
        "                                                species_tag), sep=\"\\t\", \n",
        "            col.names = T, row.names = T)"
      ],
      "metadata": {
        "id": "gUPPp_9gl_lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gene Set Enrichment analysis (GSEA)\n",
        "\n",
        "GeneOntology (GO) terms enrichment analysis was performed for the lists of differentially expressed protein-coding sequences. In present analysis, we selected only biological processes with p-value less than 0.01 and with more than 10 sequences. The analysis was also performed in R using topGO, rrvgo, dplyr packages and ggplot2, wordcloud, viridis packages for visualization. We utilised Drosophila melanogaster database as the closest avaliable relative to the anomuran Pagurus minutus (Arthropoda: Tetraconata) to simplify the redundance of GO sets by grouping similar terms based on their semantic similarity\n",
        "\n",
        "Tre following scripts were used for female crabs wordcloud and topGO visualisations."
      ],
      "metadata": {
        "id": "RpQJMO_emILQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "### Libraries ###\n",
        "library(wordcloud)\n",
        "library(dplyr)\n",
        "library(viridis)\n",
        "\n",
        "### Input files ###\n",
        "infected_reduced <- read.csv2(\"Pmin_Infected_fem_overexpr_genes_reduced_GSEA_results.Dmelanogaster.tsv\", \n",
        "                             header = T, sep=\"\\t\")\n",
        "healthy_reduced <- read.csv2(\"Pmin_Healthy_fem_overexpr_genes_reduced_GSEA_results.Dmelanogaster.tsv\", \n",
        "                              header = T, sep=\"\\t\")\n",
        "species_tag <- \"Pmin\"\n",
        "set_tag <- \"over-expressed_genes\"\n",
        "\n",
        "set.seed(1234)\n",
        "\n",
        "### Processing ###\n",
        "input_list <- list(\"infected_fem\" = infected_reduced,\n",
        "                   \"healthy_fem\" = healthy_reduced)\n",
        "\n",
        "for (set in 1:length(input_list)){\n",
        "  set_reduced_terms <- count(input_list[[set]], input_list[[set]][\"parentTerm\"], sort=T)\n",
        "  colnames(set_reduced_terms) <- c(\"word\", \"freq\")\n",
        "  viridis_colors <- viridis(n = length(set_reduced_terms$word))\n",
        "  # visual #\n",
        "  pdf(file=sprintf(\"%s_%s_%s.wordcloud.pdf\", species_tag, names(input_list[set]), set_tag), width = 9, height = 9)\n",
        "  set_reduced_term_cloud <- wordcloud(words=set_reduced_terms$word, freq=set_reduced_terms$freq, min.freq = 1, \n",
        "                                      max.words=length(set_reduced_terms$word), scale = c(4.25, 0.25),\n",
        "                                      random.order = F, rot.per = 0, colors = as.character(viridis_colors), ordered.colors = T)\n",
        "  dev.off()\n",
        "}"
      ],
      "metadata": {
        "id": "hJwnj22JnYJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "### Libraries ###\n",
        "library(topGO)\n",
        "library(dplyr)\n",
        "library(rrvgo)\n",
        "library(ggplot2)\n",
        "\n",
        "species_tag <- \"Pmin\"\n",
        "options(ggrepel.max.overlaps = Inf)\n",
        "gene_ont <- read.csv2(\"data/emapper_annotations.tsv\", skip = 4,\n",
        "                           header = T, sep=\"\\t\")\n",
        "gene_ontuni <- gene_ont[, c(\"X.query\", \"GOs\")]\n",
        "gene_ontuni <- gene_ontuni[grep(\"GO\", gene_ontuni$GOs),]\n",
        "names(gene_ontuni) <- NULL\n",
        "\n",
        "gene_ontuni <- as.data.frame(sapply(gene_ontuni, function(x)  as.character(x)))\n",
        "\n",
        "write.table(gene_ontuni, file = sprintf(\"%s_GeneOntologyUniverse_filtered.txt\", \n",
        "                                      species_tag), sep=\"\\t\",\n",
        "            col.names = FALSE, row.names = FALSE)\n",
        "\n",
        "### Input data ###\n",
        "species_geneID2GO <- readMappings(file=\"data/Pmin_go.txt\")\n",
        "species_geneNames <- names(species_geneID2GO)\n",
        "\n",
        "molsign_tab <- read.csv2(\"Pmin_RNentropy_significant_results.tsv\", \n",
        "                         header = T, sep=\"\\t\")\n",
        "\n",
        "stages <- colnames(molsign_tab[, 4:ncol(molsign_tab)])\n",
        "\n",
        "### Analysis ###\n",
        "for (stage in stages){\n",
        "  stage_molsign <- dplyr::select(subset(molsign_tab, molsign_tab[stage] == 1), GeneIDs)\n",
        "  stage_all_genes <- factor(as.integer(species_geneNames %in% stage_molsign$GeneIDs))\n",
        "  names(stage_all_genes) <- species_geneNames\n",
        "  ## Biological Processes (BP) ##\n",
        "  GOdata_stage_BP <- new(\"topGOdata\", ontology=\"BP\", allGenes=stage_all_genes,\n",
        "                         annot=annFUN.gene2GO, gene2GO=species_geneID2GO)\n",
        "  resultsFisher_stage_BP <- runTest(GOdata_stage_BP, algorithm=\"classic\", \n",
        "                                    statistic=\"fisher\")\n",
        "  resultsFisher_stage_BP_df <- as.data.frame(score(resultsFisher_stage_BP))\n",
        "  colnames(resultsFisher_stage_BP_df) <- \"P-values\"\n",
        "  resultsFisher_stage_BP_df_subset <- subset(resultsFisher_stage_BP_df, \n",
        "                                             resultsFisher_stage_BP_df$`P-values`\n",
        "                                             < 0.01)\n",
        "  results_stage_BP <- GenTable(GOdata_stage_BP, \n",
        "                               classicFisher=resultsFisher_stage_BP,\n",
        "                               ranksOf=\"classicFisher\", \n",
        "                               topNodes =length(resultsFisher_stage_BP_df_subset$`P-values`))\n",
        "  results_stage_BP_short <- subset(results_stage_BP, Significant >= 10)\n",
        "  output_file_name <- sprintf(\"%s_%s_overexpr_genes_GOenrichment_BP_Fisher.min_10_genes.tsv\", \n",
        "                              species_tag, stage)\n",
        "  write.table(results_stage_BP_short, file=output_file_name, sep=\"\\t\", quote=F, \n",
        "              col.names = T, row.names = F)\n",
        "  ## Reduced Terms ##\n",
        "  stage_simMatrix <- calculateSimMatrix(results_stage_BP_short[[\"GO.ID\"]], \n",
        "                                        orgdb = \"org.Dm.eg.db\", \n",
        "                                        ont=\"BP\", method=\"Rel\")\n",
        "  stage_classicFisher <- gsub(\"< \", \"\", results_stage_BP_short[[\"classicFisher\"]])\n",
        "  stage_scores <- setNames(-log10(as.numeric(as.character(stage_classicFisher))), \n",
        "                           results_stage_BP_short[[\"GO.ID\"]])\n",
        "  stage_reducedTerms <- reduceSimMatrix(stage_simMatrix, stage_scores, threshold = 0.7, \n",
        "                                        orgdb=\"org.Dm.eg.db\")\n",
        "  stage_reducedTerms_selected <- dplyr::select(stage_reducedTerms, parent, score, parentTerm)\n",
        "  # duplication removing: #\n",
        "  stage_reducedTerms_uniq <- stage_reducedTerms_selected %>% \n",
        "    group_by(parentTerm) %>%\n",
        "    filter(row_number() == 1)\n",
        "  # Preparation for visualization #\n",
        "  stage_reducedTerms_uniq_df <- as.data.frame(stage_reducedTerms_uniq)\n",
        "  stage_reducedTerms_uniq_df$GOid_and_desc <- paste(stage_reducedTerms_uniq_df$parent, \n",
        "                                                    \"|\", stage_reducedTerms_uniq_df$parentTerm)\n",
        "  stage_reducedTerms_uniq_df$score_signif <- signif(stage_reducedTerms_uniq_df$score, \n",
        "                                                    digits = 3)\n",
        "  # Visualization #\n",
        "  # Plot #\n",
        "  pdf(file=sprintf(\"%s_%s_overexpr_genes_reduced_GSEA_results.Dmelanogaster_parent_GOterms.pdf\", species_tag, stage), width = 10, height = 12)\n",
        "  result_plot <- stage_reducedTerms_uniq_df %>%\n",
        "    arrange(score) %>%\n",
        "    mutate(GOid_and_desc=factor(GOid_and_desc, levels=GOid_and_desc)) %>% \n",
        "    ggplot(aes(x=score, y=GOid_and_desc, fill=as.factor(score_signif))) + \n",
        "    geom_point(alpha=0.9, shape=21, size=5, color=\"black\") + theme_bw() + \n",
        "    # legend.position = \"right\", axis.text=element_text(size=12, face=\"bold\")\n",
        "    theme(legend.position = \"none\", \n",
        "          plot.title = element_text(hjust = 0.5, size = 15, face=\"bold\"), \n",
        "          axis.title.x = element_text(size=13, face=\"bold\"), \n",
        "          axis.title.y = element_text(size=13, face=\"bold\")) + \n",
        "    xlab(\"-log10(Fisher's Test p-values)\") + ylab(\"Parental Gene Ontology terms (Fly)\") + \n",
        "    ggtitle(sprintf(\"Reduced GSEA results: \\n %s %s molecular signature \\n (over-expressed genes)\", \n",
        "                    species_tag, stage)) + labs(fill=\"Log-transformed scores\")\n",
        "  print(result_plot)\n",
        "  dev.off()\n",
        "  # ScatterPlot #\n",
        "  pdf(file=sprintf(\"%s_%s_overexpr_genes_reduced_GSEA_results.Dmelanogaster.scatterPlot.pdf\", \n",
        "                   species_tag, stage), width = 15, height = 15)\n",
        "  scatter <- scatterPlot(stage_simMatrix, stage_reducedTerms, size=\"score\", addLabel = TRUE, \n",
        "                         labelSize = 5)\n",
        "  print(scatter)\n",
        "  dev.off()\n",
        "  # Output writing #\n",
        "  write.table(stage_reducedTerms, \n",
        "              file=sprintf(\"%s_%s_overexpr_genes_reduced_GSEA_results.Dmelanogaster.tsv\", \n",
        "                           species_tag, stage),\n",
        "              sep=\"\\t\", quote = F, col.names = T, row.names = F)\n",
        "}\n",
        "# "
      ],
      "metadata": {
        "id": "jv-vHu2cnjX2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}